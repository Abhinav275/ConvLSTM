{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings():\n",
    "    def __init__(self, vocab, emd_dims):\n",
    "        self.vocab = vocab\n",
    "        self.embeds = nn.Embedding(len(vocab), emd_dims)\n",
    "    \n",
    "    def get_embedding(self, word):\n",
    "        lookup_tensor = torch.tensor(self.vocab[word], dtype = torch.long)\n",
    "        return self.embeds(lookup_tensor)\n",
    "    \n",
    "    def vocab_size():\n",
    "        return len(self.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/coco/coco_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/coco/coco_test_all.csv\n",
      "./data/coco/coco_val_all.csv\n",
      "./data/coco/coco_train_all.csv\n",
      "./data/bing/bing_train_all.csv\n",
      "./data/bing/bing_val_all.csv\n",
      "./data/bing/bing_test_all.csv\n",
      "./data/flickr/flickr_train_all.csv\n",
      "./data/flickr/flickr_val_all.csv\n",
      "./data/flickr/flickr_test_all.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = ['coco','bing','flickr']\n",
    "dataframes = []\n",
    "for f in data_folder:\n",
    "    files = os.listdir('./data/'+f)   \n",
    "    for path in files:\n",
    "        if('.csv' in path):\n",
    "            csv_path = './data/'+f+'/'+path\n",
    "            print(csv_path)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            dataframes.append(df)\n",
    "len(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14815"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dataframes, axis = 0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12098"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = list(df['questions'])\n",
    "freq = {}\n",
    "for q in questions:\n",
    "    for question in q.split('---'):\n",
    "        wordlist = nltk.word_tokenize(question)\n",
    "        for word in wordlist:\n",
    "            if(word not in freq):\n",
    "                freq[word] = 1\n",
    "            else:\n",
    "                freq[word] += 1\n",
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5061"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "counter = 0\n",
    "for key in freq.keys():\n",
    "    if freq[key]>=3:\n",
    "        vocab[key] = counter\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "vocab['<unk>'] = counter\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = list(model.features)[-1]\n",
    "# m = nn.ModuleList(features).eval()\n",
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vqgnet(nn.Module):\n",
    "    def __init__(self, num_lstm_layers, embedding, max_len):\n",
    "        super(Vqgnet, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.model_vgg = models.vgg19(pretrained=True)\n",
    "        for p in self.model_vgg.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.features = self.model_vgg.classifier[:-1]\n",
    "        self.transform_layer = nn.Linear(4096, 512)\n",
    "        self.feature_to_word = nn.Linear(512, self.embedding.vocab_size())\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        self.lstm = nn.LSTM(512, 512)\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def forward(image, question):\n",
    "        # teacher forcing using gt question\n",
    "        \n",
    "        # getting image features\n",
    "        x = self.features(image)\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.transform_layer(x))\n",
    "        \n",
    "        cell_state = torch.randn(1, 1, 512)\n",
    "        que = []\n",
    "        # embedding phase\n",
    "        for i in range(len(question)):\n",
    "            word = question[i]\n",
    "            embed = self.embedding.get_embedding(word)\n",
    "            output, cell_state = self.lstm(embed, cell_state)\n",
    "            que.append(output)\n",
    "    \n",
    "    def test(image):\n",
    "        # get image features\n",
    "        x = self.features(image)\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.tranform_layer(x))\n",
    "        \n",
    "        cell_state = torch.randn(1, 1, 512)\n",
    "        que = []\n",
    "        output = ''\n",
    "        predicted_question = []\n",
    "        # generate question\n",
    "        while output != self.embedding.get_eoq():\n",
    "            x, cell_state = self.lstm(x, cell_state)\n",
    "            output = F.softmax(x)\n",
    "            predicted_question.append(output)\n",
    "        \n",
    "        return predicted_question\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model.classifier[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
